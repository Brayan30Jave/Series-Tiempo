library(Metrics)
# Calcular las métricas de precisión
rmse <- rmse(serie_tiempo, modelo_holt_winters$fitted)
mae <- mae(serie_tiempo, modelo_holt_winters$fitted)
mape <- mape(serie_tiempo, modelo_holt_winters$fitted) * 100
# Imprimir las métricas
cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")
cat("MAPE:", mape, "%", "\n")
# Cargar la librería forecast para predicciones
library(forecast)
library(Metrics)
# Leer los datos y transformar los datos
datos <- readxl::read_excel("MUESTRA SERIE TIEMPO.xlsx")
datos$transaction_date <- as.Date(datos$transaction_date, origin="1899-12-30")
datos <- aggregate(quantity ~ transaction_date, data = datos, FUN = sum)
# Convertir los datos a un objeto de serie temporal
serie_tiempo <- ts(datos$quantity, start = c(2017, 1), end = c(2020, 12), frequency = 12)
# Visualizar la serie temporal
plot(serie_tiempo, main = "Serie Temporal de Tiempo", ylab = "Tiempo", xlab = "Fecha")
# Suavizamiento exponencial simple
suavizado_simple <- HoltWinters(serie_tiempo, beta = FALSE, gamma = FALSE)
plot(suavizado_simple, main = "Suavizamiento Exponencial Simple")
# Aplicar el modelo Holt-Winters con componentes de tendencia y estacionalidad
modelo_holt_winters <- HoltWinters(serie_tiempo)
plot(modelo_holt_winters, main = "Modelo Holt-Winters con Tendencia y Estacionalidad")
# Calcular las métricas de precisión
rmse <- rmse(serie_tiempo, modelo_holt_winters$fitted)
mae <- mae(serie_tiempo, modelo_holt_winters$fitted)
mape <- mape(serie_tiempo, modelo_holt_winters$fitted) * 100
# Imprimir las métricas
cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")
cat("MAPE:", mape, "%", "\n")
# Generar pronósticos para los próximos 12 períodos
pronostico <- forecast(modelo_holt_winters, h = 12)
plot(pronostico, main = "Pronóstico de la Serie Temporal con Holt-Winters")
# Cargar la librería forecast para predicciones
library(forecast)
library(Metrics)
# Leer los datos y transformar los datos
datos <- readxl::read_excel("MUESTRA SERIE TIEMPO.xlsx")
datos$transaction_date <- as.Date(datos$transaction_date, origin="1899-12-30")
datos <- aggregate(quantity ~ transaction_date, data = datos, FUN = sum)
# Convertir los datos a un objeto de serie temporal
serie_tiempo <- ts(datos$quantity, start = c(2017, 1), end = c(2020, 12), frequency = 12)
# Visualizar la serie temporal
plot(serie_tiempo, main = "Serie Temporal de Tiempo", ylab = "Tiempo", xlab = "Fecha")
# Suavizamiento exponencial simple
suavizado_simple <- HoltWinters(serie_tiempo, beta = FALSE, gamma = FALSE)
plot(suavizado_simple, main = "Suavizamiento Exponencial Simple")
# Aplicar el modelo Holt-Winters con componentes de tendencia y estacionalidad
modelo_holt_winters <- HoltWinters(serie_tiempo)
plot(modelo_holt_winters, main = "Modelo Holt-Winters con Tendencia y Estacionalidad")
# Calcular las métricas de precisión
rmse <- rmse(serie_tiempo, modelo_holt_winters$fitted)
mae <- mae(serie_tiempo, modelo_holt_winters$fitted)
mape <- mape(serie_tiempo, modelo_holt_winters$fitted) * 100
# Imprimir las métricas
cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")
cat("MAPE:", mape, "%", "\n")
# Generar pronósticos para los próximos 12 períodos
pronostico <- forecast(modelo_holt_winters, h = 12)
plot(pronostico, main = "Pronóstico de la Serie Temporal con Holt-Winters")
# Cargar la librería forecast para predicciones
library(forecast)
library(Metrics)
# Leer los datos y transformar los datos
datos <- readxl::read_excel("MUESTRA SERIE TIEMPO.xlsx")
datos$transaction_date <- as.Date(datos$transaction_date, origin="1899-12-30")
datos <- aggregate(quantity ~ transaction_date, data = datos, FUN = sum)
# Convertir los datos a un objeto de serie temporal
serie_tiempo <- ts(datos$quantity, start = c(2017, 1), end = c(2020, 12), frequency = 12)
# Visualizar la serie temporal
plot(serie_tiempo, main = "Serie Temporal de Tiempo", ylab = "Tiempo", xlab = "Fecha")
# Suavizamiento exponencial simple
suavizado_simple <- HoltWinters(serie_tiempo, beta = FALSE, gamma = FALSE)
plot(suavizado_simple, main = "Suavizamiento Exponencial Simple")
# Aplicar el modelo Holt-Winters con componentes de tendencia y estacionalidad
modelo_holt_winters <- HoltWinters(serie_tiempo)
plot(modelo_holt_winters, main = "Modelo Holt-Winters con Tendencia y Estacionalidad")
# Calcular las métricas de precisión
rmse <- rmse(serie_tiempo, modelo_holt_winters$fitted)
mae <- mae(serie_tiempo, modelo_holt_winters$fitted)
mape <- mape(serie_tiempo, modelo_holt_winters$fitted) * 100
# Imprimir las métricas
cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")
cat("MAPE:", mape, "%", "\n")
# Generar pronósticos para los próximos 12 períodos
pronostico <- forecast(modelo_holt_winters, h = 12)
plot(pronostico, main = "Pronóstico de la Serie Temporal con Holt-Winters")
# Leer los datos y transformar los datos
datos <- readxl::read_excel("MUESTRA SERIE TIEMPO.xlsx")
datos$transaction_date <- as.Date(datos$transaction_date, origin="1899-12-30")
datos <- aggregate(quantity ~ transaction_date, data = datos, FUN = sum)
# Convertir los datos a un objeto de serie temporal
serie_tiempo <- ts(datos$quantity, start = c(2017, 1), end = c(2020, 12), frequency = 12)
# Visualizar la serie temporal
plot(serie_tiempo, main = "Serie Temporal de Tiempo", ylab = "Tiempo", xlab = "Fecha")
# Convertir los datos a un objeto de serie temporal
serie_tiempo <- ts(datos$quantity, start = c(2017, 1), end = c(2020, 12), frequency = 12)
# Leer los datos y transformar los datos
datos <- readxl::read_excel("MUESTRA SERIE TIEMPO.xlsx")
datos$transaction_date <- as.Date(datos$transaction_date, origin="1899-12-30")
datos <- aggregate(quantity ~ transaction_date, data = datos, FUN = sum)
# Convertir los datos a un objeto de serie temporal
serie_tiempo <- ts(datos$quantity, start = c(2017, 1), end = c(2020, 12), frequency = 12)
# Visualizar la serie temporal
plot(serie_tiempo, main = "Serie Temporal de Tiempo", ylab = "Tiempo", xlab = "Fecha")
# Cargar la librería forecast para predicciones
library(forecast)
library(Metrics)
# Leer los datos y transformar los datos
datos <- readxl::read_excel("MUESTRA SERIE TIEMPO.xlsx")
datos$transaction_date <- as.Date(datos$transaction_date, origin="1899-12-30")
datos <- aggregate(quantity ~ transaction_date, data = datos, FUN = sum)
# Convertir los datos a un objeto de serie temporal
serie_tiempo <- ts(datos$quantity, start = c(2017, 1), end = c(2020, 12), frequency = 12)
# Visualizar la serie temporal
plot(serie_tiempo, main = "Serie Temporal de Tiempo", ylab = "Tiempo", xlab = "Fecha")
# Suavizamiento exponencial simple
suavizado_simple <- HoltWinters(serie_tiempo, beta = FALSE, gamma = FALSE)
plot(suavizado_simple, main = "Suavizamiento Exponencial Simple")
# Aplicar el modelo Holt-Winters con componentes de tendencia y estacionalidad
modelo_holt_winters <- HoltWinters(serie_tiempo)
plot(modelo_holt_winters, main = "Modelo Holt-Winters con Tendencia y Estacionalidad")
# Calcular las métricas de precisión
rmse <- rmse(serie_tiempo, modelo_holt_winters$fitted)
mae <- mae(serie_tiempo, modelo_holt_winters$fitted)
mape <- mape(serie_tiempo, modelo_holt_winters$fitted) * 100
# Imprimir las métricas
cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")
cat("MAPE:", mape, "%", "\n")
# Generar pronósticos para los próximos 12 períodos
pronostico <- forecast(modelo_holt_winters, h = 12)
plot(pronostico, main = "Pronóstico de la Serie Temporal con Holt-Winters")
library(forecast)  # Para funciones de pronóstico y series de tiempo
library(tseries)   # Para pruebas de estacionariedad
datos <- readxl::read_excel("MUESTRA SERIE TIEMPO.xlsx")
# Asumiendo que la primera columna es la fecha y la segunda la variable de interés
datos_ts <- ts(datos$variable, frequency = 12, start = c(2020, 1))
# Asumiendo que la primera columna es la fecha y la segunda la variable de interés
datos_ts <- ts(datos$quantity, frequency = 12, start = c(2017, 1), end = c(2020,12))
str(datos)
datos$transaction_date <- as.Date(datos$transaction_date, origin="1899-12-30")
str(datos)
# Asumiendo que la primera columna es la fecha y la segunda la variable de interés
datos_ts <- ts(datos$quantity, frequency = 12, start = c(2017, 1), end = c(2020,12))
plot(datos_ts)  # Gráfico de la serie de tiempo
acf(datos_ts)   # Función de autocorrelación
pacf(datos_ts)  # Función de autocorrelación parcial
adf.test(datos_ts)
modelo_auto <- auto.arima(datos_ts, ic = "aic")  # Puedes usar "bic" también
summary(modelo_auto)
checkresiduals(modelo_auto)  # O checkresiduals(modelo_sarima)
pronóstico <- forecast(modelo_auto, h = 12)  # Pronóstico para los próximos 12 periodos
plot(pronóstico)
modelo_auto <- auto.arima(datos_ts, ic = "bic")  # Puedes usar "bic" también
checkresiduals(modelo_auto)  # O checkresiduals(modelo_sarima)
pronóstico <- forecast(modelo_auto, h = 12)  # Pronóstico para los próximos 12 periodos
plot(pronóstico)
plot(datos_ts)  # Gráfico de la serie de tiempo
acf(datos_ts)   # Función de autocorrelación
pacf(datos_ts)  # Función de autocorrelación parcial
adf.test(datos_ts)
#Si la prueba indica que la serie no es estacionaria, deberás diferenciarla:
datos_ts_diff <- diff(datos_ts)
modelo_auto <- auto.arima(datos_ts, ic = "bic")  # Puedes usar "bic" también
summary(modelo_auto)
checkresiduals(modelo_auto)  # O checkresiduals(modelo_sarima)
pronóstico <- forecast(modelo_auto, h = 12)  # Pronóstico para los próximos 12 periodos
plot(pronóstico)
datos$transaction_date <- as.Date(datos$transaction_date, origin="1899-12-30")
str(datos)
# Asumiendo que la primera columna es la fecha y la segunda la variable de interés
datos_ts <- ts(datos$quantity, frequency = 12, start = c(2017, 1), end = c(2020,12))
plot(datos_ts)  # Gráfico de la serie de tiempo
acf(datos_ts)   # Función de autocorrelación
pacf(datos_ts)  # Función de autocorrelación parcial
adf.test(datos_ts)
#Si la prueba indica que la serie no es estacionaria, deberás diferenciarla:
datos_ts_diff <- diff(datos_ts)
modelo_auto <- auto.arima(datos_ts, ic = "bic")  # Puedes usar "bic" también
summary(modelo_auto)
checkresiduals(modelo_auto)  # O checkresiduals(modelo_sarima)
pronóstico <- forecast(modelo_auto, h = 12)  # Pronóstico para los próximos 12 periodos
plot(pronóstico)
datos <- readxl::read_excel("MUESTRA SERIE TIEMPO.xlsx")
datos$transaction_date <- as.Date(datos$transaction_date, origin="1899-12-30")
str(datos)
# Asumiendo que la primera columna es la fecha y la segunda la variable de interés
datos_ts <- ts(datos$quantity, frequency = 12, start = c(2017, 1), end = c(2020,12))
plot(datos_ts)  # Gráfico de la serie de tiempo
acf(datos_ts)   # Función de autocorrelación
pacf(datos_ts)  # Función de autocorrelación parcial
adf.test(datos_ts)
#Si la prueba indica que la serie no es estacionaria, deberás diferenciarla:
datos_ts_diff <- diff(datos_ts)
modelo_auto <- auto.arima(datos_ts, ic = "bic")  # Puedes usar "bic" también
summary(modelo_auto)
checkresiduals(modelo_auto)  # O checkresiduals(modelo_sarima)
pronóstico <- forecast(modelo_auto, h = 12)  # Pronóstico para los próximos 12 periodos
plot(pronóstico)
sum(datos$quantity)
datos <- readxl::read_excel("MUESTRA SERIE TIEMPO.xlsx")
sum(datos$quantity)
datos$transaction_date <- as.Date(datos$transaction_date, origin="1899-12-30")
str(datos)
# Asumiendo que la primera columna es la fecha y la segunda la variable de interés
datos_ts <- ts(datos$quantity, frequency = 12, start = c(2017, 1), end = c(2020,12))
plot(datos_ts)  # Gráfico de la serie de tiempo
acf(datos_ts)   # Función de autocorrelación
pacf(datos_ts)  # Función de autocorrelación parcial
adf.test(datos_ts)
#Si la prueba indica que la serie no es estacionaria, deberás diferenciarla:
datos_ts_diff <- diff(datos_ts)
modelo_auto <- auto.arima(datos_ts, ic = "bic")  # Puedes usar "bic" también
summary(modelo_auto)
checkresiduals(modelo_auto)  # O checkresiduals(modelo_sarima)
pronóstico <- forecast(modelo_auto, h = 12)  # Pronóstico para los próximos 12 periodos
plot(pronóstico)
adf.test(datos_ts_diff)
modelo_auto <- auto.arima(datos_ts_diff, ic = "bic")  # Puedes usar "bic" también
summary(modelo_auto)
checkresiduals(modelo_auto)  # O checkresiduals(modelo_sarima)
pronóstico <- forecast(modelo_auto, h = 12)  # Pronóstico para los próximos 12 periodos
plot(pronóstico)
datos<-readxl::read_excel("MUESTRA SERIE TIEMPO.xlsx")
library(forecast)
library(forecast)
library(tseries)
library(timsac)
if(!require("forecast")) install.packages("forecast")
if(!require("tseries")) install.packages("tseries")
if(!require("timsac")) install.packages("timsac")
if(!require("ggplot2")) install.packages("ggplot2")
if(!require("changepoint")) install.packages("changepoint")
if(!require("tsoutliers")) install.packages("tsoutliers")
library(forecast)
library(tseries)
library(timsac)
library(ggplot2)
library(changepoint)
library(tsoutliers)
datos<-readxl::read_excel("MUESTRA SERIE TIEMPO.xlsx")
datos$transaction_date <- as.Date(datos$transaction_date, origin = "1900-01-01")
datos <- datos[order(datos$transaction_date), ]
# Aggregate the quantity sold per day (or other metric as needed)
agg_data <- aggregate(quantity ~ transaction_date, data = datos, sum)
# Convert the data to a time series starting from the earliest date
start_year <- as.numeric(format(min(agg_data$transaction_date), "%Y"))
start_day <- as.numeric(format(min(agg_data$transaction_date), "%j"))
# Create a time series object from the aggregated data
quantity.ts <- ts(agg_data$quantity, start = c(start_year, start_day), frequency = 365)
# Plot the original time series
plot(quantity.ts, main="Sales Quantity Time Series", ylab="Quantity", xlab="Year")
# Test for stationarity using Augmented Dickey-Fuller test
adf_result <- adf.test(quantity.ts, alternative = "stationary")
print(adf_result)
# ACF and PACF plots to determine AR and MA terms
acf(quantity.ts, main="ACF of Sales Quantity")
pacf(quantity.ts, main="PACF of Sales Quantity")
# Fit ARIMA model using auto.arima
model <- auto.arima(quantity.ts)
print(model)
# Forecast the next 12 time periods
forecast_result <- forecast(model, h = 12)
print(forecast_result)
# Plot the forecast
plot(forecast_result, main="Sales Quantity Forecast", ylab="Quantity", xlab="Year")
# Detect outliers in the time series
dat.ts <- ts(quantity.ts, frequency=1)
data.ts.outliers <- tso(dat.ts)
data.ts.outliers <- tso(dat.ts)
plot(data.ts.outliers)
# Detect change points in the time series
mval <- cpt.mean(quantity.ts, method = "AMOC")
# Detect change points in the time series
mval <- cpt.mean(quantity.ts, method = "AMOC")
plot(mval, type = "l", cpt.col = "blue", xlab = "Index", main = "Change Point Detection")
# Instalar el paquete si no lo tienes
install.packages("readxl")
# Instalar el paquete si no lo tienes
install.packages("readxl")
# Cargar el paquete
library(readxl)
# Leer el archivo Excel
data <- MUESTRA_SERIE_TIEMPO
# Instalar el paquete si no lo tienes
install.packages("readxl")
install.packages("readxl")
# Cargar el paquete
library(readxl)
# Leer el archivo Excel
data <- MUESTRA_SERIE_TIEMPO.xlsx
# Leer el archivo Excel
data <- MUESTRA_SERIE_TIEMPO.xlsx
# Leer el archivo Excel
data <- read_excel("MUESTRA SERIE TIEMPO.xlsx")
# Verificar los datos cargados
head(data)
str(data)
data$transaction_date <- as.Date(data$transaction_date, format = "%Y-%m-%d") # Ajusta el formato si es necesario
library(dplyr)
library(tidyr)
daily_data <- data %>%
group_by(transaction_date) %>%
summarise(quantity = sum(quantity, na.rm = TRUE)) %>%
complete(transaction_date = seq(min(transaction_date), max(transaction_date), by = "day"),
fill = list(quantity = 0))
quantity_ts <- ts(daily_data$quantity, start = c(as.numeric(format(min(daily_data$transaction_date), "%Y")),
as.numeric(format(min(daily_data$transaction_date), "%j"))),
frequency = 365)
train_size <- floor(0.8 * length(quantity_ts))
train <- quantity_ts[1:train_size]
test <- quantity_ts[(train_size + 1):length(quantity_ts)]
normalize <- function(x) (x - min(x)) / (max(x) - min(x))
denormalize <- function(x, min_val, max_val) x * (max_val - min_val) + min_val
train_norm <- normalize(train)
test_norm <- normalize(test)
library(RSNNS)
install.packages("RSNNS")
library(RSNNS)
# Preparar datos para el modelo Elman
inputs <- embed(train_norm, 2)[, 2, drop = FALSE]
outputs <- embed(train_norm, 2)[, 1]
# Entrenar el modelo
elman_model <- elman(
inputs,
outputs,
size = c(5),             # Número de neuronas en la capa oculta
learnFuncParams = c(0.1),# Tasa de aprendizaje
maxit = 1000             # Iteraciones máximas
)
# Predecir en el conjunto de prueba
inputs_test <- embed(test_norm, 2)[, 2, drop = FALSE]
predictions_elman <- predict(elman_model, inputs_test)
# Desnormalizar las predicciones
predictions_elman <- denormalize(predictions_elman, min(train), max(train))
# Grafica de predicción vrs realidad
# Graficar predicciones frente a los valores reales
plot(test, type = "l", col = "black", main = "Predicciones vs Realidad", xlab = "Tiempo", ylab = "Cantidad")
lines(predictions_elman, col = "blue", lty = 2)  # Predicciones del modelo Elman
# Grafica de predicción vrs realidad
# Graficar predicciones frente a los valores reales
plot(test, type = "l", col = "black", main = "Predicciones vs Realidad", xlab = "Tiempo", ylab = "Cantidad")
lines(predictions_elman, col = "blue", lty = 2)  # Predicciones del modelo Elman
lines(predictions_elman, col = "blue", lty = 2)  # Predicciones del modelo Elman
lines(predictions_elman, col = "blue", lty = 2)  # Predicciones del modelo Elman
View(elman_model)
# Grafica de predicción vrs realidad
# Graficar predicciones frente a los valores reales
plot(test, type = "l", col = "black", main = "Predicciones vs Realidad", xlab = "Tiempo", ylab = "Cantidad")
lines(predictions_elman, col = "blue", lty = 2)  # Predicciones del modelo Elman
# Grafica de predicción vrs realidad
# Graficar predicciones frente a los valores reales
plot(test, type = "l", col = "black", main = "Predicciones vs Realidad", xlab = "Tiempo", ylab = "Cantidad")
# Desnormalizar las predicciones
predictions_elman <- denormalize(predictions_elman, min(train), max(train))
# Grafica de predicción vrs realidad
# Graficar predicciones frente a los valores reales
plot(test, type = "l", col = "black", main = "Predicciones vs Realidad", xlab = "Tiempo", ylab = "Cantidad")
lines(predictions_elman, col = "blue", lty = 2)  # Predicciones del modelo Elman
lines(predictions_elman, col = "blue", lty = 2)  # Predicciones del modelo Elman
View(predictions_elman)
View(predictions_elman)
lines(predictions_elman, col = "blue", lty = 2)  # Predicciones del modelo Elman
lines(predictions_elman, col = "blue", lty = 2)  # Predicciones del modelo Elman
lines(predictions_elman, col = "blue", lty = 2)  # Predicciones del modelo Elman
# Instalar el paquete si no lo tienes
install.packages("readxl")
install.packages("RSNNS")
# Cargar el paquete
library(readxl)
# Leer el archivo Excel
data <- read_excel("MUESTRA SERIE TIEMPO.xlsx")
# Verificar los datos cargados
head(data)
str(data)
#convertir la variable "quantity" en una serie de tiempo diaria"
data$transaction_date <- as.Date(data$transaction_date, format = "%Y-%m-%d") # Ajusta el formato si es necesario
#agrupar los datos por dia
library(dplyr)
library(tidyr)
# Crear una serie diaria completa
daily_data <- data %>%
group_by(transaction_date) %>%
summarise(quantity = sum(quantity, na.rm = TRUE)) %>%
complete(transaction_date = seq(min(transaction_date), max(transaction_date), by = "day"),
fill = list(quantity = 0))
# Crear la serie temporal
quantity_ts <- ts(daily_data$quantity, start = c(as.numeric(format(min(daily_data$transaction_date), "%Y")),
as.numeric(format(min(daily_data$transaction_date), "%j"))),
frequency = 365)
#dividir los datos en entrenamiento y prueba
train_size <- floor(0.8 * length(quantity_ts))
train <- quantity_ts[1:train_size]
test <- quantity_ts[(train_size + 1):length(quantity_ts)]
#Normalizar los datos
normalize <- function(x) (x - min(x)) / (max(x) - min(x))
denormalize <- function(x, min_val, max_val) x * (max_val - min_val) + min_val
train_norm <- normalize(train)
test_norm <- normalize(test)
#ELMAN MODEL
library(RSNNS)
# Preparar datos para el modelo Elman
inputs <- embed(train_norm, 2)[, 2, drop = FALSE]
outputs <- embed(train_norm, 2)[, 1]
# Entrenar el modelo
elman_model <- elman(
inputs,
outputs,
size = c(5),             # Número de neuronas en la capa oculta
learnFuncParams = c(0.1),# Tasa de aprendizaje
maxit = 1000             # Iteraciones máximas
)
# Predecir en el conjunto de prueba
inputs_test <- embed(test_norm, 2)[, 2, drop = FALSE]
predictions_elman <- predict(elman_model, inputs_test)
# Desnormalizar las predicciones
predictions_elman <- denormalize(predictions_elman, min(train), max(train))
# Grafica de predicción vrs realidad
# Graficar predicciones frente a los valores reales
plot(test, type = "l", col = "black", main = "Predicciones vs Realidad", xlab = "Tiempo", ylab = "Cantidad")
lines(predictions_elman, col = "blue", lty = 2)  # Predicciones del modelo Elman
legend("topright", legend = c("Realidad", "Elman"), col = c("black", "blue"), lty = 1:2)
# GRafica de residuos
# Asegurarte de que 'predictions_elman' tenga el mismo tamaño que 'test'
predictions_elman <- predictions_elman[1:length(test)]
# Calcular los residuos
residuals <- test - predictions_elman
# Graficar los residuos
plot(residuals, type = "o", col = "red", main = "Residuos del Modelo Elman", xlab = "Tiempo", ylab = "Residuo")
# Metricas
# Calcular el RMSE
rmse <- function(real, predicted) sqrt(mean((real - predicted)^2))
rmse_value <- rmse(test, predictions_elman)
print(paste("RMSE:", rmse_value))
# Verificar valores NA en 'test' y 'predictions_elman'
sum(is.na(test))  # Ver cuántos valores faltan en el conjunto de prueba
sum(is.na(predictions_elman))  # Ver cuántos valores faltan en las predicciones
# Eliminar valores NA de 'test' y 'predictions_elman'
valid_indices <- complete.cases(test, predictions_elman)
test <- test[valid_indices]
predictions_elman <- predictions_elman[valid_indices]
# Recalcular el RMSE
rmse_value <- sqrt(mean((test - predictions_elman)^2))
print(paste("RMSE:", rmse_value))
# Calcular el MAE
mae <- function(real, predicted) mean(abs(real - predicted))
mae_value <- mae(test, predictions_elman)
print(paste("MAE:", mae_value))
# Calcular el R²
r2_value <- 1 - sum((test - predictions_elman)^2) / sum((test - mean(test))^2)
print(paste("R²:", r2_value))
##JORDAN
# Entrenar el modelo Jordan
jordan_model <- jordan(
inputs,
outputs,
size = c(5),             # Número de neuronas en la capa oculta
learnFuncParams = c(0.1),# Tasa de aprendizaje
maxit = 1000             # Iteraciones máximas
)
# Predecir en el conjunto de prueba
predictions_jordan <- predict(jordan_model, inputs_test)
# Desnormalizar las predicciones
predictions_jordan <- denormalize(predictions_jordan, min(train), max(train))
# Calcular RMSE
rmse <- function(real, predicted) sqrt(mean((real - predicted)^2))
rmse_elman <- rmse(test, predictions_elman)
rmse_jordan <- rmse(test, predictions_jordan)
# Graficar resultados
plot(test, type = "l", col = "black", main = "Predicciones vs Realidad")
lines(predictions_elman, col = "blue", lty = 2)  # Elman
lines(predictions_jordan, col = "red", lty = 2)  # Jordan
legend("topright", legend = c("Realidad", "Elman", "Jordan"),
col = c("black", "blue", "red"), lty = 1:2)
#Comparación de métricas
# Cálculo de RMSE para Elman
rmse_elman <- sqrt(mean((test - predictions_elman)^2))
# Cálculo de RMSE para Jordan
rmse_jordan <- sqrt(mean((test - predictions_jordan)^2))
# Imprimir los resultados
print(paste("RMSE Elman:", rmse_elman))
print(paste("RMSE Jordan:", rmse_jordan))
# Cálculo de MAE para Elman
mae_elman <- mean(abs(test - predictions_elman))
# Cálculo de MAE para Jordan
mae_jordan <- mean(abs(test - predictions_jordan))
# Imprimir los resultados
print(paste("MAE Elman:", mae_elman))
print(paste("MAE Jordan:", mae_jordan))
# Cálculo de R² para Elman
r_squared_elman <- 1 - sum((test - predictions_elman)^2) / sum((test - mean(test))^2)
# Cálculo de R² para Jordan
r_squared_jordan <- 1 - sum((test - predictions_jordan)^2) / sum((test - mean(test))^2)
# Imprimir los resultados
print(paste("R² Elman:", r_squared_elman))
print(paste("R² Jordan:", r_squared_jordan))
# Graficar las predicciones de ambos modelos
plot(test, type = "l", col = "black", main = "Comparación de Predicciones: Elman vs. Jordan",
xlab = "Tiempo", ylab = "Cantidad")
lines(predictions_elman, col = "blue", lty = 2)
lines(predictions_jordan, col = "red", lty = 3)
legend("topright", legend = c("Realidad", "Predicciones Elman", "Predicciones Jordan"),
col = c("black", "blue", "red"), lty = 1:3)
install.packages("RSNNS")
install.packages("readxl")
